---
title: "Homework 4"
output:
  html_document: default
  html_notebook: default
---

## Problem 2

### 2.2

Read the training data and test data:
```{r}
load("../HW03/zip.RData")
```

Apply the Naive Bayes classifier:
```{r}
library(e1071)
dat.nb <- naiveBayes(V1 ~ ., data=dat$train)
y.test.nb <- predict(dat.nb, newdata=dat$test)
```

Confusion matrix:
```{r}
table(y.test.nb, dat$test[,1])
```

Misclassification rate:
```{r}
mean(y.test.nb != dat$test[,1])
```

## Problem 3

### 3.1

5-fold cross validation:
```{r}
generate_indices <- function(n, k, seed=10) {
  set.seed(seed)
  ind <- rep(0, n)
  a <- split(sample(1:n), 1:k)
  for (j in 1:k) { ind[a[[j]]] <- j }
  ind
}

cv.5fold <- function(data, predictor, seed=10) {
  ind <- generate_indices(nrow(data), 5, seed)
  errors <- sapply(1:5, function(j) {
    set.seed(seed)
    y.hat <- predictor(data[ind != j,], data[ind == j,])
    mean(y.hat != data[ind == j,1])
  })
  mean(errors)
}
```

```{r}
library(class)
knn.predictor <- function(train, test, k) {
  knn(train[,-1], test[,-1], train[,1], k=k, prob=F)
}
```

Calculate training error, 5-fold CV error and test error for kNN classifier with different `k` values:
```{r warning=FALSE}
train.errors <- rep(0, 15)
cv.errors <- rep(0, 15)
test.errors <- rep(0, 15)
for (k in 1:15) {
  predictor <- function(train, test) { knn.predictor(train, test, k) }
  cv.errors[k] <- cv.5fold(dat$train, predictor)
  set.seed(10)
  train.errors[k] <- mean(knn(dat$train[,-1], dat$train[,-1], dat$train[,1], k=k, prob=F) != dat$train[,1])
  test.errors[k] <- mean(knn(dat$train[,-1], dat$test[,-1], dat$train[,1], k=k, prob=F) != dat$test[,1])
  cat("k =", k, ", train error =", train.errors[k], ", cv error =", cv.errors[k], ", test error =", test.errors[k], "\n")
}
```

```{r}
library(ggplot2)
library(reshape2)
errors <- data.frame(k=1:15, train=train.errors, cv=cv.errors, test=test.errors)
errors <- melt(errors, id="k")
ggplot(errors) + geom_line(aes(k, value, color=variable)) + labs(y="error", color="error type")
```

Alternatively, use the `caret` package to train kNN classifier:
```{r}
library(caret)
set.seed(1234)
train.control <- trainControl(method="repeatedcv", number=5, repeats=1)
dat.knn <- train(V1 ~ ., data=dat$train, method="knn", trControl=train.control, tuneGrid=expand.grid(k=1:15))
dat.knn
```


### 3.2
`k`=1 performs the best based on the training error:
```{r}
which(train.errors == min(train.errors))
```

`k`=1, 5 and 7 perform the best based on the test error:
```{r}
which(test.errors == min(test.errors))
```

`k`=3 performs the best based on the CV error:
```{r}
which(cv.errors == min(cv.errors))
```

### 3.3

Run CV ten times with different random seeds for `k`=4 (which yields the lowest CV error above):
```{r warning=FALSE}
cv.errors2 <- rep(0, 10)
for (seed in 1:10) {
  set.seed(seed)
  predictor <- function(train, test) { knn.predictor(train, test, 4) }
  cv.errors2[seed] <- cv.5fold(dat$train, predictor, seed)
}
cv.errors2
```

The CV errors are different when using different random seeds.

### 3.4

The function to generate equal sample sizes for each fold was already implemented above in 3.1. Check with `n`=12 (12 samples) and `k`=5 (5 folds):
```{r warning=FALSE}
for (seed in 1:5) {
  ind <- generate_indices(12, 5, seed)
  print(ind)
}
```

## Problem 4

### 4.1

Number of support vectors for different values of the cost:
```{r}
nSV <- c()
costs <- 10^(-5:5)
for (cost in costs) {
  data.svm <- svm(V1 ~ ., data=dat$train, cost=cost, scale=F)
  nSV <- c(nSV, data.svm$tot.nSV)
}
nSV
```

Plot the number of support vectors vs. C:
```{r}
ggplot(data=data.frame(costs,nSV), aes(costs, nSV)) +
  geom_line() + scale_x_log10() + labs(x="cost", y="number of support vectors")
```

### 4.2

Calculate 5-fold CV errors for different cost values:
```{r warning=FALSE}
cv.errors <- c()
for (cost in costs) {
  predictor <- function(train, test) {
    data.svm <- svm(V1 ~ ., data=train, cost=cost, scale=F)
    predict(data.svm, test)
  }
  cv.error <- cv.5fold(dat$train, predictor, seed=10)
  cv.errors <- c(cv.errors, cv.error)
  cat("cost =", cost, ", cv error =", cv.error, "\n")
}
```

The following cost values have the lowest CV error:
```{r}
costs[which(cv.errors == min(cv.errors))]
```

### 4.3
Here we use cost = 10:
```{r}
data.svm <- svm(V1 ~ ., data=dat$train, cost=10, scale=F)
y.test.svm <- predict(data.svm, dat$test)
mean(y.test.svm != dat$test[,1])
```

Confusion matrix for the test data:
```{r}
table(y.test.svm, dat$test[,1])
```

Function for plotting the digit data as an image:
```{r}
conv.image <- function(vec)
{
mat <- matrix(as.numeric(vec), nrow=16, ncol=16)
mat <- -mat[, 16 : 1]
par(mar=c(0, 0, 0, 0))
image(mat, col=gray(seq(0, 1, 0.01)), xaxt='n', yaxt='n')
}
```

One's that are misclassified as three's:
```{r}
one.as.three <- intersect(which(y.test.svm==3), which(dat$test[,1]==1))
conv.image(dat$test[one.as.three[1], -1])

for (i in 1:length(one.as.three)) {
  pdf(paste0('one.as.three', i, '.pdf'))
  conv.image(dat$test[one.as.three[i], -1])
  dev.off()
}
```

One's that are misclassified as five's:
```{r}
one.as.five <- intersect(which(y.test.svm==5), which(dat$test[,1]==1))
conv.image(dat$test[one.as.five[1], -1])

for (i in 1:length(one.as.five)) {
  pdf(paste0('one.as.five', i, '.pdf'))
  conv.image(dat$test[one.as.five[i], -1])
  dev.off()
}
```

Three's that are misclassified as five's:
```{r}
three.as.five <- intersect(which(y.test.svm==5), which(dat$test[,1]==3))
conv.image(dat$test[three.as.five[1], -1])

for (i in 1:length(three.as.five)) {
  pdf(paste0('three.as.five', i, '.pdf'))
  conv.image(dat$test[three.as.five[i], -1])
  dev.off()
}
```

Five's that are misclassified as three's:
```{r}
five.as.three <- intersect(which(y.test.svm==3), which(dat$test[,1]==5))
conv.image(dat$test[five.as.three[1], -1])

for (i in 1:length(five.as.three)) {
  pdf(paste0('five.as.three', i, '.pdf'))
  conv.image(dat$test[five.as.three[i], -1])
  dev.off()
}
```

### 4.4
#### Radial basis kenerl
```{r warning=FALSE}
costs <- 10^(-2:2)
gammas <- 10^(-5:5)
for (cost in costs) {
  for (gamma in gammas) {
    predictor <- function(train, test) {
      data.svm <- svm(V1 ~ ., data=train, cost=cost, gamma=gamma, scale=F)
      predict(data.svm, test)
    }
    cv.error <- cv.5fold(dat$train, predictor)
    cat("cost =", cost, ", gamma =", gamma, ", cv error =", cv.error, "\n")
  }
}
```


We find that `cost` = 4 - 128 and `gamma` = 0.0078125 is one combination of parameters that have (0.005903646).
```{r warning=FALSE}
costs <- 2^(-1:7)
gammas <- 2^(-9:-4)
for (cost in costs) {
  for (gamma in gammas) {
    predictor <- function(train, test) {
      data.svm <- svm(V1 ~ ., data=train, cost=cost, gamma=gamma, scale=F)
      predict(data.svm, test)
    }
    cv.errors <- sapply(1:10, function(i) cv.5fold(dat$train, predictor, seed=i))
    cat("cost =", cost, ", gamma =", gamma, ", cv error =", mean(cv.errors), "\n")
  }
}
```

Check the 5-fold CV error:
```{r}
cv.error <- 0
for (seed in 1:20) {
  set.seed(seed)
  ind <- sample(1:nrow(dat$train))
  train.ind <- ind[c(1:as.integer(nrow(dat$train)*.8))]
  data.svm <- svm(V1 ~ ., data=dat$train[train.ind,], cost=8, gamma=0.0078125, scale=F)
  cv.error <- cv.error + mean(predict(data.svm, dat$train[-train.ind,]) != dat$train[-train.ind,1])
}
cv.error/20
```
#### Polynomial kernel
`cost` is set to 8 as in the above RBF kernel case:
```{r warning=FALSE}
gammas <- 10^(-5:1)
coef0s <- 10^(-5:5)
degrees <- c(2, 3)
for (gamma in gammas) {
  for (coef0 in coef0s) {
    for (degree in degrees) {
      predictor <- function(train, test) {
        data.svm <- svm(V1 ~ ., data=train, kernel="polynomial",
                        cost=8, gamma=gamma, coef0=coef0, degree=degree, scale=F)
        predict(data.svm, test)
      }
      cv.error <- cv.5fold(dat$train, predictor)
      cat("gamma =", gamma, ", coef0 =", coef0, ", degree =", degree, ", cv error =", cv.error, "\n")
    }
  }
}
```

We find that `cost` = 8 (preset), `gamma` = 0.125, `coef0` = 0.01 and `degree` = 3 is one combination of parameters that have the lowest CV error (0.005678116).
```{r warning=FALSE}
gammas <- 2^(-6:3)
coef0s <- 10^(-4:0)
degrees <- c(2, 3)
for (gamma in gammas) {
  for (coef0 in coef0s) {
    for (degree in degrees) {
      predictor <- function(train, test) {
        data.svm <- svm(V1 ~ ., data=train, kernel="polynomial",
                        cost=8, gamma=gamma, coef0=coef0, degree=degree, scale=F)
        predict(data.svm, test)
      }
      cv.errors <- sapply(1:10, function(i) cv.5fold(dat$train, predictor, seed=i))
      cat("gamma =", gamma, ", coef0 =", coef0, ", degree =", degree, ", cv error =", mean(cv.errors), "\n")
    }
  }
}
```

Check the 5-fold CV error:
```{r}
cv.error <- 0
for (seed in 1:20) {
  set.seed(seed)
  ind <- sample(1:nrow(dat$train))
  train.ind <- ind[c(1:as.integer(nrow(dat$train)*.8))]
  data.svm <- svm(V1 ~ ., data=dat$train[train.ind,], kernel="polynomial",
                  cost=8, gamma=0.125, coef0=0.01, degree=3, scale=F)
  cv.error <- cv.error + mean(predict(data.svm, dat$train[-train.ind,]) != dat$train[-train.ind,1])
}
cv.error/20
```

## Problem 5

### 5.1

Generate a dataset with 500 samples:
```{r}
set.seed(10)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- ifelse(x1^2 - x2^2 > 0, 1, 0)
dat <- data.frame(x1, x2, y)
dat$y <- as.factor(dat$y)
```

Plot the sample points:
```{r}
ggplot(dat, aes(x=x1, y=x2, color=y)) + geom_point() + coord_fixed()
```

### 5.2

Train the data with four classifiers:

#### Linear SVM
```{r}
dat.svmLinear <- svm(y ~ x1+x2, data=dat, kernel="linear")
dat$svmLinear <- predict(dat.svmLinear, dat)
ggplot(dat, aes(x=x1, y=x2, color=svmLinear)) + geom_point() + coord_fixed()
```

#### Nonlinear SVM
```{r}
dat.svmRadial <- svm(y ~ x1+x2, data=dat)
dat$svmRadial <- predict(dat.svmRadial, dat)
ggplot(dat, aes(x=x1, y=x2, color=svmRadial)) + geom_point() + coord_fixed()
```

#### LDA using `x1` and `x2`
```{r}
library(MASS)
dat.lda <- lda(y ~ x1+x2, data=dat)
dat$lda <- predict(dat.lda, dat)$class
ggplot(dat, aes(x=x1, y=x2, color=lda)) + geom_point() + coord_fixed()
```

#### LDA using `x1`, `x2` and their squares
```{r}
dat$x1sq <- dat$x1^2
dat$x2sq <- dat$x2^2
dat.ldaNonlinear <- lda(y ~ x1+x2+x1sq+x2sq, data=dat)
dat$ldaNonlinear <- predict(dat.ldaNonlinear, dat)$class
ggplot(dat, aes(x=x1, y=x2, color=ldaNonlinear)) + geom_point() + coord_fixed()
```

The decision boundary is nonlinear, so only SVM with nonlinear kernels and LDA with nonlinear transformations of freatures can accurately predict it.